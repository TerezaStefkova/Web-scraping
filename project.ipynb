{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598893102433",
   "display_name": "Python 3.8.5 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Toy model\" for job posting scraping\n",
    "\n",
    "This is a basic system that illustrates the process of web scraping. I used request library to acces urls, Beautiful soup and regular expressions to parse webpage content and natural language toolkit to handle extracted text. In the project I followed this idea:\n",
    "\n",
    "## Building the model\n",
    "\n",
    "1. Create corpus of job postings - I restricted myself to job postings about industry accessed from page jobs.cz. For simplicity I used only about 40 postings.\n",
    "2. Analyze this corpus - tokenize, normalize and filter the corpus with the aim of extracting the key words - most frequent words in the corpus\n",
    "3. Define criteria for a text to be a job posting - based on the length of the text and number of keywords\n",
    "\n",
    "## Testing the model\n",
    "\n",
    "1. Access company's website and find the page with career postings. This model only works for pages where postings are displayed on internal pages.\n",
    "2. Find first two levels of internal links on the career page - filter links in header and footer (by ignoring links displayed on the main page, as they do not link to job postings and contain header and footer links). On top of that, I assume that job postings can be accessed navigating two subsequent pages from the career page\n",
    "3. Assess if the page content for the above links correspond to a job posting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk import FreqDist\t\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #access jobs.cz, \"strojirentsvi\"\n",
    "    try:\n",
    "        r = requests.get('https://www.jobs.cz/prace/strojirenstvi/')\n",
    "\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        raise SystemExit(e)\n",
    "    #initialize an instance of beautifulsoup\n",
    "    soup=BeautifulSoup(r.text)\n",
    "\n",
    "    #find all links on the page\n",
    "    links=[]\n",
    "    for link in soup.find_all('a'):\n",
    "        links.append(link.get('href'))\n",
    "    \n",
    "    #filter links corresponding to job postings (are in the form: https://www.jobs.cz/rpd/...)\n",
    "    test_links=[]\n",
    "    for link in links:\n",
    "        if re.search('https://www.jobs.cz/rpd/.',link):\n",
    "            test_links.append(link)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "38"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#create a list of job postings accessed on jobs.cz\n",
    "job_postings=[]\n",
    "for i in range(0,len(test_links)):\n",
    "    try:\n",
    "        r = requests.get('{}'.format(test_links[i]))\n",
    "\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        raise SystemExit(e)\n",
    "\n",
    "    #get text content from the webpage    \n",
    "    soup=BeautifulSoup(r.text)    \n",
    "    job_postings.append(soup.get_text())\n",
    "\n",
    "#check number of postings\n",
    "len(job_postings)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess job postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove redundant characters\n",
    "def clean_text(text):\n",
    "     replaced_text=re.sub(r'\\n',' ',text)        \n",
    "     replaced_text = re.sub(r'-', ' ', replaced_text)      \n",
    "     replaced_text = re.sub(r',', ' ', replaced_text)           \n",
    "     replaced_text = re.sub(r'？', '', replaced_text)\n",
    "     replaced_text = re.sub(r'!', '', replaced_text)\n",
    "     replaced_text = re.sub(r'►', '', replaced_text)\n",
    "     replaced_text = re.sub(r'/', '', replaced_text)\n",
    "     replaced_text = re.sub(r'•', '', replaced_text)\n",
    "     replaced_text = re.sub(r':', '', replaced_text)\n",
    "     replaced_text = re.sub(r'[.]', ' ', replaced_text)\n",
    "     replaced_text = re.sub(r'[(]', '', replaced_text)  \n",
    "     replaced_text = re.sub(r'[)]', '', replaced_text)\n",
    "     replaced_text = re.sub(r'\\xa0', ' ', replaced_text)      \n",
    "     replaced_text = re.sub(r'　', ' ', replaced_text)\n",
    "     replaced_text=replaced_text.lower()\n",
    "        \n",
    "     return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of tokens with stop words removed\n",
    "#I did not create a stopword list for Czech language, I used the condition on number of characters instead\n",
    "\n",
    "def trim_test_postings(domains,job_postings):\n",
    "    #get tokens\n",
    "    tokens=[]\n",
    "    for i in range(0,len(domains)):\n",
    "        tokens = tokens+word_tokenize(clean_text(job_postings[i]))    \n",
    "\n",
    "    #filter stopwords    \n",
    "    stopwords_removed=[]\n",
    "    for item in tokens:\n",
    "        if len(item)>3 and len(item)<9:\n",
    "            stopwords_removed.append(item)\n",
    "    return stopwords_removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating a corpus of preprocessed job postings\n",
    "corpus=nltk.Text(trim_test_postings(test_links,job_postings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that finds the 150 most common words in a corpus\n",
    "def frequent_words(text):\n",
    "    fdist = FreqDist(text) \n",
    "    most_common_tuple=fdist.most_common(150)\n",
    "    #print(most_common_tuple)\n",
    "\n",
    "    #create a list of most common words\n",
    "    most_common_words=[]\n",
    "    for i in range(0,len(most_common_tuple)):\n",
    "        most_common_words.append(most_common_tuple[i][0])\n",
    "    return most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('práce', 218), ('pracovní', 94), ('firmy', 93), ('týdnů', 81), ('vstup', 66), ('spol', 65), ('lidé', 57), ('nebo', 57), ('poměru', 55), ('pracovat', 49), ('jsme', 46), ('vzdělání', 45), ('nabídky', 42), ('plný', 40), ('úvazek', 39), ('skupiny', 39), ('kraj', 39), ('průmysl', 38), ('okres', 38), ('historie', 37), ('menu', 37), ('odborné', 37), ('vyučení', 37), ('podmínky', 37), ('pozice', 35), ('ochrana', 35), ('rodiny', 35), ('firemní', 35), ('smlouva', 34), ('sdílet', 34), ('členem', 34), ('nábor', 34), ('člen', 34), ('všechna', 34), ('brigády', 33), ('odpovědí', 33), ('zařazeno', 33), ('přidat', 33), ('napsat', 33), ('jobsmůj', 33), ('firmypro', 33), ('námpro', 33), ('cookies', 33), ('soukromí', 33), ('english', 33), ('lmcjobs', 33), ('czslušná', 33), ('czfirmy', 33), ('očima', 33), ('jednom', 33), ('czonline', 33), ('alma', 33), ('career', 33), ('práva', 33), ('obsahu', 33), ('chytrou', 33), ('matej', 33), ('benefity', 33), ('máte', 32), ('praha', 32), ('vztahu', 32), ('pozici', 32), ('dobu', 32), ('znalost', 31), ('školení', 31), ('strojů', 31), ('výroby', 30), ('stroje', 30), ('dovolená', 30), ('práci', 29), ('česká', 29), ('technik', 29), ('kurzy', 28), ('tuto', 27), ('nabídku', 27), ('výrobní', 27), ('naše', 26), ('kontrola', 25), ('adresa', 25), ('šanci', 24), ('zatím', 24), ('méně', 24), ('oblasti', 24), ('možnost', 24), ('továrna', 24), ('výroba', 23), ('můžete', 23), ('oboru', 23), ('jazyky', 22), ('délka', 22), ('obchodní', 22), ('brno', 21), ('vhodná', 19), ('provozu', 19), ('výrobě', 19), ('více', 19), ('kvality', 18), ('systémů', 18), ('akce', 18), ('jejich', 17), ('týmu', 17), ('doby', 17), ('bude', 17), ('řízení', 16), ('attl', 16), ('linek', 16), ('praxe', 16), ('platplat', 16), ('měsíc', 16), ('závodní', 16), ('zařízení', 16), ('rámci', 15), ('operátor', 15), ('vývoj', 15), ('chotěšov', 15), ('nových', 14), ('náplň', 14), ('plat', 14), ('předních', 14), ('výrobců', 14), ('vaše', 14), ('hannifin', 14), ('obsluha', 13), ('firma', 13), ('servisní', 13), ('výkonu', 13), ('budete', 13), ('nabídka', 13), ('řešení', 13), ('včetně', 13), ('určitou', 13), ('čeština', 12), ('platové', 12), ('naší', 12), ('nářadí', 12), ('odpověď', 11), ('středně', 11), ('sídlem', 11), ('maturity', 11), ('elektro', 11), ('další', 11), ('mobilní', 11), ('zaujala', 11), ('propojek', 11), ('dovolené', 11), ('klienty', 11), ('boels', 11), ('místa', 10), ('nabízíme', 10), ('nové', 10)]\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['práce',\n 'pracovní',\n 'firmy',\n 'týdnů',\n 'vstup',\n 'spol',\n 'lidé',\n 'nebo',\n 'poměru',\n 'pracovat',\n 'jsme',\n 'vzdělání',\n 'nabídky',\n 'plný',\n 'úvazek',\n 'skupiny',\n 'kraj',\n 'průmysl',\n 'okres',\n 'historie',\n 'menu',\n 'odborné',\n 'vyučení',\n 'podmínky',\n 'pozice',\n 'ochrana',\n 'rodiny',\n 'firemní',\n 'smlouva',\n 'sdílet',\n 'členem',\n 'nábor',\n 'člen',\n 'všechna',\n 'brigády',\n 'odpovědí',\n 'zařazeno',\n 'přidat',\n 'napsat',\n 'jobsmůj',\n 'firmypro',\n 'námpro',\n 'cookies',\n 'soukromí',\n 'english',\n 'lmcjobs',\n 'czslušná',\n 'czfirmy',\n 'očima',\n 'jednom',\n 'czonline',\n 'alma',\n 'career',\n 'práva',\n 'obsahu',\n 'chytrou',\n 'matej',\n 'benefity',\n 'máte',\n 'praha',\n 'vztahu',\n 'pozici',\n 'dobu',\n 'znalost',\n 'školení',\n 'strojů',\n 'výroby',\n 'stroje',\n 'dovolená',\n 'práci',\n 'česká',\n 'technik',\n 'kurzy',\n 'tuto',\n 'nabídku',\n 'výrobní',\n 'naše',\n 'kontrola',\n 'adresa',\n 'šanci',\n 'zatím',\n 'méně',\n 'oblasti',\n 'možnost',\n 'továrna',\n 'výroba',\n 'můžete',\n 'oboru',\n 'jazyky',\n 'délka',\n 'obchodní',\n 'brno',\n 'vhodná',\n 'provozu',\n 'výrobě',\n 'více',\n 'kvality',\n 'systémů',\n 'akce',\n 'jejich',\n 'týmu',\n 'doby',\n 'bude',\n 'řízení',\n 'attl',\n 'linek',\n 'praxe',\n 'platplat',\n 'měsíc',\n 'závodní',\n 'zařízení',\n 'rámci',\n 'operátor',\n 'vývoj',\n 'chotěšov',\n 'nových',\n 'náplň',\n 'plat',\n 'předních',\n 'výrobců',\n 'vaše',\n 'hannifin',\n 'obsluha',\n 'firma',\n 'servisní',\n 'výkonu',\n 'budete',\n 'nabídka',\n 'řešení',\n 'včetně',\n 'určitou',\n 'čeština',\n 'platové',\n 'naší',\n 'nářadí',\n 'odpověď',\n 'středně',\n 'sídlem',\n 'maturity',\n 'elektro',\n 'další',\n 'mobilní',\n 'zaujala',\n 'propojek',\n 'dovolené',\n 'klienty',\n 'boels',\n 'místa',\n 'nabízíme',\n 'nové']"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "#creating list of words that will serve as the key words in the analysis\n",
    "corpus_words=frequent_words(corpus)\n",
    "\n",
    "corpus_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I defined a function to evaluate if a certain text is a job posting or not as follows. The current model is oversimplified as I set a very low theshold to work well with my particular problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(page_text):\n",
    "    #get tokens\n",
    "    tokens = word_tokenize(clean_text(page_text)) \n",
    "\n",
    "    #filter stopwords\n",
    "    stopwords_removed=[]\n",
    "    for item in tokens:\n",
    "        if len(item)>3 and len(item)<9:\n",
    "            stopwords_removed.append(item)\n",
    "    return stopwords_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if it is a job posting. Criteria: number of words greater than 200, number of words corresponding to key words greater than 50.\n",
    "def job_posting(text,corpus_words):\n",
    "    score=0\n",
    "    \n",
    "    # preprocessed list of words on the given webpage\n",
    "    bag_of_words=trim(text)\n",
    "    \n",
    "    #if word is in corpus than score rises\n",
    "    for item in bag_of_words:\n",
    "        if item in corpus_words:\n",
    "            score=score+1\n",
    "    \n",
    "    #check conditions on job postings\n",
    "    \n",
    "    if len(bag_of_words) > 100 and score/len(bag_of_words)>0.1:\n",
    "        return True\n",
    "    else:\n",
    "        return False    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n"
    }
   ],
   "source": [
    "#check if the evaluation function works well with the training job postings\n",
    "for posting in job_postings:    \n",
    "    print(job_posting(posting,corpus_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model\n",
    "\n",
    "Test the model on an example of a website https://www.rdrymarov.cz/\n",
    "\n",
    "This model is oversimplified as it only works with pages where job postings are displayed on internal pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "page='https://www.rdrymarov.cz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def access_url(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        raise SystemExit(e)\n",
    "    \n",
    "    formatted_url=r.url\n",
    "    visited_pages.add(r.url)\n",
    "    soup=BeautifulSoup(r.text)\n",
    "\n",
    "    #parse url to get the precise domain\n",
    "    parsed_url=urlparse(formatted_url)\n",
    "    domain=parsed_url.netloc\n",
    "\n",
    "    return domain, soup, formatted_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize set of pages already visited\n",
    "visited_pages=set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all links on the given page\n",
    "def get_links(soup):\n",
    "    links=set()\n",
    "    \n",
    "    for link in soup.find_all('a'):\n",
    "        links.add(link.get('href'))\n",
    "\n",
    "    return links    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter internal links\n",
    "def format_links(links,domain):\n",
    "    #unify the form of the links first\n",
    "    formatted_links=set()\n",
    "\n",
    "    for link in links:\n",
    "        #add domain to internal links\n",
    "        if re.search('^/',link):\n",
    "            formatted_links.add('https://{}{}'.format(domain,link)) \n",
    "        else:\n",
    "             formatted_links.add(link)\n",
    "\n",
    "    #filter internal links\n",
    "    formatted_internal_links=set()\n",
    "\n",
    "    for link in formatted_links:\n",
    "        if re.search('.{}.'.format(domain),link):\n",
    "            formatted_internal_links.add(link) \n",
    "             \n",
    "    return formatted_internal_links      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access website www.rdrymarov.cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'https://www.rdrymarov.cz/',\n 'https://www.rdrymarov.cz/cenik',\n 'https://www.rdrymarov.cz/financovani',\n 'https://www.rdrymarov.cz/fotogalerie',\n 'https://www.rdrymarov.cz/kariera',\n 'https://www.rdrymarov.cz/katalog-domu',\n 'https://www.rdrymarov.cz/kontakt',\n 'https://www.rdrymarov.cz/kubis',\n 'https://www.rdrymarov.cz/largo',\n 'https://www.rdrymarov.cz/mapa-stranek',\n 'https://www.rdrymarov.cz/mini',\n 'https://www.rdrymarov.cz/montovane-domy',\n 'https://www.rdrymarov.cz/nasi-partneri',\n 'https://www.rdrymarov.cz/nova',\n 'https://www.rdrymarov.cz/novinka-ela-s-krystofem-si-navrhli-svuj-dum-snu',\n 'https://www.rdrymarov.cz/novinka-reference-bydleni-v-bungalovu-largo-121',\n 'https://www.rdrymarov.cz/novinka-rozhovor-o-dome-kubis-74-s-manzeli-monikou-a-vladimirem',\n 'https://www.rdrymarov.cz/novinky-a-akce/projekty-rodinnych-domu-rd-rymarov',\n 'https://www.rdrymarov.cz/novinky-a-akce/rd-magazin',\n 'https://www.rdrymarov.cz/o-nas',\n 'https://www.rdrymarov.cz/podminky-pouziti',\n 'https://www.rdrymarov.cz/reference-zakazniku',\n 'https://www.rdrymarov.cz/reklamace',\n 'https://www.rdrymarov.cz/rohe',\n 'https://www.rdrymarov.cz/schemata-sten-a-stropu',\n 'https://www.rdrymarov.cz/solo',\n 'https://www.rdrymarov.cz/stavebni-dily1',\n 'https://www.rdrymarov.cz/vzorove-domy'}"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "\n",
    "domain=access_url(page)[0]\n",
    "soup=access_url(page)[1]\n",
    "links=get_links(soup)\n",
    "formatted=format_links(links,domain)\n",
    "\n",
    "#remember links shown on the homepage\n",
    "links_main_page=set(formatted)\n",
    "\n",
    "#show internal links displayed on the homepage\n",
    "links_main_page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'https://www.rdrymarov.cz/kariera'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "#find a page with job postings\n",
    "key_words=['kariera', 'prace', 'pozice', 'mista', 'zamestnani']\n",
    "\n",
    "\n",
    "for link in formatted:\n",
    "    for key_word in key_words:\n",
    "        if re.search('.{}'.format(key_word),link):\n",
    "            career=link\n",
    "\n",
    "  #link to career page\n",
    "career          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def links_to_visit(url,links_main_page,visited_pages):\n",
    "    result=access_url(url)\n",
    "\n",
    "    links=get_links(result[1])\n",
    "    formatted=format_links(links,result[0])\n",
    "\n",
    "    links=[]\n",
    "    for link in formatted:\n",
    "        if link not in visited_pages and link not in links_main_page:\n",
    "            links.append(link)\n",
    "            \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us get links accessible from https://www.rdrymarov.cz/kariera. I assume that job postings should be available within two clicks from the webpage https://www.rdrymarov.cz/kariera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loop through links accessible from https://www.rdrymarov.cz/kariera \n",
    "\n",
    "#which pages to visit?\n",
    "pages_to_visit=[]\n",
    "\n",
    "#starts with https://www.rdrymarov.cz/kariera\n",
    "pages_to_visit.append(career)\n",
    "\n",
    "i=0\n",
    "\n",
    "#list of candicates for job postings\n",
    "final_pages=[]\n",
    "\n",
    "while i<2:\n",
    "    i=i+1\n",
    "    for page in pages_to_visit:\n",
    "        linky=links_to_visit(page, links_main_page,visited_pages)\n",
    "\n",
    "        #add links to final_pages\n",
    "        for link in linky:\n",
    "            final_pages.append(link)\n",
    "        #get new links to visit    \n",
    "        pages_to_visit=linky[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['https://www.rdrymarov.cz/montaznik-ridic-autojerabu-vazac-bremen',\n 'https://www.rdrymarov.cz/montaznik-instalater-topenar',\n 'https://www.rdrymarov.cz/pokryvac',\n 'https://www.rdrymarov.cz/elektrikar',\n 'https://www.rdrymarov.cz/tesar',\n 'https://www.rdrymarov.cz/instalater-topenar',\n 'https://www.rdrymarov.cz/nova-vyrobni-linka',\n 'https://www.rdrymarov.cz/montaznik-malir',\n 'http://www.rdrymarov.cz/novinky-a-akce/projekty-rd-rymarov',\n 'https://www.rdrymarov.cz/delnik-vyroby-domu-stolar',\n 'https://www.rdrymarov.cz/stavebni-elektrikar',\n 'https://www.rdrymarov.cz/instalater-vodovodu']"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "#candidates\n",
    "final_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True https://www.rdrymarov.cz/montaznik-ridic-autojerabu-vazac-bremen\nTrue https://www.rdrymarov.cz/montaznik-instalater-topenar\nTrue https://www.rdrymarov.cz/pokryvac\nTrue https://www.rdrymarov.cz/elektrikar\nTrue https://www.rdrymarov.cz/tesar\nTrue https://www.rdrymarov.cz/instalater-topenar\nFalse https://www.rdrymarov.cz/nova-vyrobni-linka\nTrue https://www.rdrymarov.cz/montaznik-malir\nFalse http://www.rdrymarov.cz/novinky-a-akce/projekty-rd-rymarov\nTrue https://www.rdrymarov.cz/delnik-vyroby-domu-stolar\nTrue https://www.rdrymarov.cz/stavebni-elektrikar\nTrue https://www.rdrymarov.cz/instalater-vodovodu\n"
    }
   ],
   "source": [
    "#initialize set of postings\n",
    "scraped_postings=set()\n",
    "\n",
    "for link in final_pages:\n",
    "    result=access_url(link)\n",
    "    links=get_links(result[1])\n",
    "    formatted=format_links(links,result[0]) \n",
    "\n",
    "    #evaluate if the content is a job posting\n",
    "    print(job_posting(result[1].get_text(),corpus_words),link) \n",
    "\n",
    "    #if True, than add content to the set of postings   \n",
    "    if job_posting(result[1].get_text(),corpus_words):        \n",
    "        scraped_postings.add(result[1].get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#print job postings\n",
    "\n",
    "for item in scraped_postings:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This toy model was succesfully detected job postings.\n",
    "\n",
    "To be improved:\n",
    "\n",
    "1. generalization to websites with job postings on external pages\n",
    "\n",
    "2. large corpora of job postings for better evaluation\n",
    "\n",
    "3. more sophisticated evaluation method (cluster URLs to find URLs corresponding to postings?, consider n-grams and collocations?)\n",
    "\n",
    "4. use selenium library for certain tasks?\n",
    "\n",
    "Is it legal to scrape any site and how to deal with anti scraping software?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}